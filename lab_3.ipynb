{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f69d732a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 'DT'), ('paragraph', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('group', 'NN'), ('of', 'IN'), ('sentences', 'NNS'), ('with', 'IN'), ('closely', 'RB'), ('related', 'VBN'), ('ideas', 'NNS'), ('.', '.')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "sentence = \"A paragraph is a group of sentences with closely related ideas.\"\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "print(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67dfe256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A DET DT\n",
      "paragraph NOUN NN\n",
      "is AUX VBZ\n",
      "a DET DT\n",
      "group NOUN NN\n",
      "of ADP IN\n",
      "sentences NOUN NNS\n",
      "with ADP IN\n",
      "closely ADV RB\n",
      "related VERB VBN\n",
      "ideas NOUN NNS\n",
      ". PUNCT .\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"A paragraph is a group of sentences with closely related ideas.\")\n",
    "for token in doc:\n",
    "    print (token.text, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9f0969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK tags                  Spacy tags\n",
      "('Slowly', 'RB')          ('Slowly', 'ADV', 'RB')\n",
      "('we', 'PRP')          ('we', 'PRON', 'PRP')\n",
      "('unfurl', 'VBP')          ('unfurl', 'VERB', 'VBZ')\n",
      "(',', ',')          (',', 'PUNCT', ',')\n",
      "('as', 'IN')          ('as', 'ADP', 'IN')\n",
      "('lotus', 'JJ')          ('lotus', 'NOUN', 'NN')\n",
      "('flowers', 'NNS')          ('flowers', 'NOUN', 'NNS')\n",
      "('.', '.')          ('.', 'PUNCT', '.')\n",
      "('Cause', 'IN')          ('Cause', 'SCONJ', 'IN')\n",
      "('all', 'DT')          ('all', 'PRON', 'DT')\n",
      "('I', 'PRP')          ('I', 'PRON', 'PRP')\n",
      "('want', 'VBP')          ('want', 'VERB', 'VBP')\n",
      "('is', 'VBZ')          ('is', 'AUX', 'VBZ')\n",
      "('the', 'DT')          ('the', 'DET', 'DT')\n",
      "('moon', 'NN')          ('moon', 'NOUN', 'NN')\n",
      "('upon', 'IN')          ('upon', 'SCONJ', 'IN')\n",
      "('a', 'DT')          ('a', 'DET', 'DT')\n",
      "('stick', 'NN')          ('stick', 'NOUN', 'NN')\n",
      "('.', '.')          ('.', 'PUNCT', '.')\n",
      "('Just', 'NNP')          ('Just', 'ADV', 'RB')\n",
      "('to', 'TO')          ('to', 'PART', 'TO')\n",
      "('see', 'VB')          ('see', 'VERB', 'VB')\n",
      "('what', 'WP')          ('what', 'PRON', 'WP')\n",
      "('if', 'IN')          ('if', 'SCONJ', 'IN')\n",
      "(',', ',')          (',', 'PUNCT', ',')\n",
      "('Just', 'NNP')          ('Just', 'ADV', 'RB')\n",
      "('to', 'TO')          ('to', 'PART', 'TO')\n",
      "('see', 'VB')          ('see', 'VERB', 'VB')\n",
      "('what', 'WP')          ('what', 'PRON', 'WP')\n",
      "('is', 'VBZ')          ('is', 'AUX', 'VBZ')\n",
      "('.', '.')          ('.', 'PUNCT', '.')\n",
      "('I', 'PRP')          ('I', 'PRON', 'PRP')\n",
      "('ca', 'MD')          ('ca', 'AUX', 'MD')\n",
      "(\"n't\", 'RB')          (\"n't\", 'PART', 'RB')\n",
      "('kick', 'VB')          ('kick', 'VERB', 'VB')\n",
      "('your', 'PRP$')          ('your', 'PRON', 'PRP$')\n",
      "('habit', 'NN')          ('habit', 'NOUN', 'NN')\n",
      "('.', '.')          ('.', 'PUNCT', '.')\n",
      "('Just', 'NNP')          ('Just', 'ADV', 'RB')\n",
      "('to', 'TO')          ('to', 'PART', 'TO')\n",
      "('feed', 'VB')          ('feed', 'VERB', 'VB')\n",
      "('your', 'PRP$')          ('your', 'PRON', 'PRP$')\n",
      "('fast', 'NN')          ('fast', 'ADJ', 'JJ')\n",
      "('ballooning', 'NN')          ('ballooning', 'NOUN', 'NN')\n",
      "('head', 'NN')          ('head', 'NOUN', 'NN')\n",
      "('.', '.')          ('.', 'PUNCT', '.')\n",
      "('Listen', 'VB')          ('Listen', 'VERB', 'VB')\n",
      "('to', 'TO')          ('to', 'ADP', 'IN')\n",
      "('your', 'PRP$')          ('your', 'PRON', 'PRP$')\n",
      "('heart', 'NN')          ('heart', 'NOUN', 'NN')\n",
      "NLTK Noun count: 11\n",
      "Spacy Noun count: 8\n",
      "NLTK Verb count: 9\n",
      "Spacy Verb count: 9\n",
      "NLTK Adjective count: 1\n",
      "Spacy Adjective count: 1\n",
      "NLTK Adverb count: 2\n",
      "Spacy Adverb count: 5\n",
      "NLTK Pronoun count: 6\n",
      "Spacy Pronoun count: 6\n",
      "NLTK Determiner count: 3\n",
      "Spacy Determiner count: 3\n",
      "NLTK Adposition count: 4\n",
      "Spacy Adposition count: 5\n",
      "NLTK Conjunction count: 0\n",
      "Spacy Conjunction count: 0\n"
     ]
    }
   ],
   "source": [
    "str=\"Slowly we unfurl, as lotus flowers. Cause all I want is the moon upon a stick. Just to see what if, Just to see what is. I can't kick your habit. Just to feed your fast ballooning head. Listen to your heart\"\n",
    "doc = nlp(str)\n",
    "words = nltk.word_tokenize(str)\n",
    "pos_tags = nltk.pos_tag(words)\n",
    "spacy_tags=[]\n",
    "for token in doc:\n",
    "    spacy_tags.append((token.text, token.pos_, token.tag_))\n",
    "    \n",
    "print(\"NLTK tags                  Spacy tags\")\n",
    "for i in range(len(pos_tags)):\n",
    "    print(f\"{pos_tags[i]}          {spacy_tags[i]}\")\n",
    "nltk_noun=0\n",
    "nltk_verb=0\n",
    "nltk_adj=0\n",
    "nltk_adv=0\n",
    "nltk_pron=0\n",
    "nltk_det=0\n",
    "nltk_adp=0\n",
    "nltk_conj=0\n",
    "spacy_noun=0\n",
    "spacy_verb=0\n",
    "spacy_adj=0\n",
    "spacy_adv=0\n",
    "spacy_pron=0\n",
    "spacy_det=0\n",
    "spacy_adp=0\n",
    "spacy_conj=0\n",
    "\n",
    "for (i,j) in pos_tags:\n",
    "    if j.startswith('V'):\n",
    "        nltk_verb= nltk_verb+1\n",
    "    if j.startswith('N'):\n",
    "        nltk_noun=nltk_noun+1\n",
    "    if j.startswith('J'):\n",
    "        nltk_adj=nltk_adj+1\n",
    "    if j.startswith('R'):\n",
    "        nltk_adv=nltk_adv+1\n",
    "    if j.startswith('PR'):\n",
    "        nltk_pron=nltk_pron+1\n",
    "    if j.startswith('DT'):\n",
    "        nltk_det=nltk_det+1\n",
    "    if j.startswith('IN'):\n",
    "        nltk_adp=nltk_adp+1\n",
    "    if j.startswith('CC'):\n",
    "        nltk_conj=nltk_conj+1\n",
    "for i,j,k in spacy_tags:\n",
    "    if k.startswith('V'):\n",
    "        spacy_verb= spacy_verb+1\n",
    "    if k.startswith('N'):\n",
    "        spacy_noun=spacy_noun+1\n",
    "    if k.startswith('J'):\n",
    "        spacy_adj=spacy_adj+1\n",
    "    if k.startswith('R'):\n",
    "        spacy_adv=spacy_adv+1\n",
    "    if k.startswith('PR'):\n",
    "        spacy_pron=spacy_pron+1\n",
    "    if k.startswith('DT'):\n",
    "        spacy_det=spacy_det+1\n",
    "    if k.startswith('IN'):\n",
    "        spacy_adp=spacy_adp+1\n",
    "    if k.startswith('CC'):\n",
    "        spacy_conj=spacy_conj+1\n",
    "\n",
    "print(\"NLTK Noun count:\",nltk_noun)\n",
    "print(\"Spacy Noun count:\",spacy_noun)  \n",
    "print(\"NLTK Verb count:\",nltk_verb)\n",
    "print(\"Spacy Verb count:\",spacy_verb)\n",
    "print(\"NLTK Adjective count:\",nltk_adj)\n",
    "print(\"Spacy Adjective count:\",spacy_adj)   \n",
    "print(\"NLTK Adverb count:\",nltk_adv)\n",
    "print(\"Spacy Adverb count:\",spacy_adv)\n",
    "print(\"NLTK Pronoun count:\",nltk_pron)\n",
    "print(\"Spacy Pronoun count:\",spacy_pron)\n",
    "print(\"NLTK Determiner count:\",nltk_det)\n",
    "print(\"Spacy Determiner count:\",spacy_det)\n",
    "print(\"NLTK Adposition count:\",nltk_adp)\n",
    "print(\"Spacy Adposition count:\",spacy_adp)\n",
    "print(\"NLTK Conjunction count:\",nltk_conj)\n",
    "print(\"Spacy Conjunction count:\",spacy_conj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
