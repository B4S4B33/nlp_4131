{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0e57c34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>summaries</th>\n",
       "      <th>terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
       "      <td>Stereo matching is one of the widely used tech...</td>\n",
       "      <td>['cs.CV', 'cs.LG']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
       "      <td>The recent advancements in artificial intellig...</td>\n",
       "      <td>['cs.CV', 'cs.AI', 'cs.LG']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
       "      <td>In this paper, we proposed a novel mutual cons...</td>\n",
       "      <td>['cs.CV', 'cs.AI']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
       "      <td>Consistency training has proven to be an advan...</td>\n",
       "      <td>['cs.CV']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Background-Foreground Segmentation for Interio...</td>\n",
       "      <td>To ensure safety in automated driving, the cor...</td>\n",
       "      <td>['cs.CV', 'cs.LG']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              titles  \\\n",
       "0  Survey on Semantic Stereo Matching / Semantic ...   \n",
       "1  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
       "2  Enforcing Mutual Consistency of Hard Regions f...   \n",
       "3  Parameter Decoupling Strategy for Semi-supervi...   \n",
       "4  Background-Foreground Segmentation for Interio...   \n",
       "\n",
       "                                           summaries  \\\n",
       "0  Stereo matching is one of the widely used tech...   \n",
       "1  The recent advancements in artificial intellig...   \n",
       "2  In this paper, we proposed a novel mutual cons...   \n",
       "3  Consistency training has proven to be an advan...   \n",
       "4  To ensure safety in automated driving, the cor...   \n",
       "\n",
       "                         terms  \n",
       "0           ['cs.CV', 'cs.LG']  \n",
       "1  ['cs.CV', 'cs.AI', 'cs.LG']  \n",
       "2           ['cs.CV', 'cs.AI']  \n",
       "3                    ['cs.CV']  \n",
       "4           ['cs.CV', 'cs.LG']  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "nltk.download('punkt')\n",
    "data= pd.read_csv('arxiv_data.csv', engine='python', nrows=1000)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "202ecc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\" \n",
    "        \"\\U0001F300-\\U0001F5FF\" \n",
    "        \"\\U0001F680-\\U0001F6FF\"\n",
    "        \"\\U0001F1E0-\\U0001F1FF\"\n",
    "        \"\\U00002702-\\U000027B0\"\n",
    "        \"\\U000024C2-\\U0001F251\"\n",
    "        \"\\U0001f926-\\U0001f937\"\n",
    "        \"\\U00010000-\\U0010ffff\"\n",
    "        \"\\u2640-\\u2642\"\n",
    "        \"\\u2600-\\u2B55\"\n",
    "        \"\\u200d\"\n",
    "        \"\\u23cf\"\n",
    "        \"\\u23e9\"\n",
    "        \"\\u231a\"\n",
    "        \"\\ufe0f\" \n",
    "        \"\\u3030\"\n",
    "        \"]+\", re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2f6b9613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>summaries</th>\n",
       "      <th>terms</th>\n",
       "      <th>processed_summaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
       "      <td>Stereo matching is one of the widely used tech...</td>\n",
       "      <td>['cs.CV', 'cs.LG']</td>\n",
       "      <td>stereo matching is one of the widely used tech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
       "      <td>The recent advancements in artificial intellig...</td>\n",
       "      <td>['cs.CV', 'cs.AI', 'cs.LG']</td>\n",
       "      <td>the recent advancements in artificial intellig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
       "      <td>In this paper, we proposed a novel mutual cons...</td>\n",
       "      <td>['cs.CV', 'cs.AI']</td>\n",
       "      <td>in this paper we proposed a novel mutual consi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
       "      <td>Consistency training has proven to be an advan...</td>\n",
       "      <td>['cs.CV']</td>\n",
       "      <td>consistency training has proven to be an advan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Background-Foreground Segmentation for Interio...</td>\n",
       "      <td>To ensure safety in automated driving, the cor...</td>\n",
       "      <td>['cs.CV', 'cs.LG']</td>\n",
       "      <td>to ensure safety in automated driving the corr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              titles  \\\n",
       "0  Survey on Semantic Stereo Matching / Semantic ...   \n",
       "1  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
       "2  Enforcing Mutual Consistency of Hard Regions f...   \n",
       "3  Parameter Decoupling Strategy for Semi-supervi...   \n",
       "4  Background-Foreground Segmentation for Interio...   \n",
       "\n",
       "                                           summaries  \\\n",
       "0  Stereo matching is one of the widely used tech...   \n",
       "1  The recent advancements in artificial intellig...   \n",
       "2  In this paper, we proposed a novel mutual cons...   \n",
       "3  Consistency training has proven to be an advan...   \n",
       "4  To ensure safety in automated driving, the cor...   \n",
       "\n",
       "                         terms  \\\n",
       "0           ['cs.CV', 'cs.LG']   \n",
       "1  ['cs.CV', 'cs.AI', 'cs.LG']   \n",
       "2           ['cs.CV', 'cs.AI']   \n",
       "3                    ['cs.CV']   \n",
       "4           ['cs.CV', 'cs.LG']   \n",
       "\n",
       "                                 processed_summaries  \n",
       "0  stereo matching is one of the widely used tech...  \n",
       "1  the recent advancements in artificial intellig...  \n",
       "2  in this paper we proposed a novel mutual consi...  \n",
       "3  consistency training has proven to be an advan...  \n",
       "4  to ensure safety in automated driving the corr...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['processed_summaries'] = data['summaries'].apply(preprocess_text)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "56bf257c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>summaries</th>\n",
       "      <th>terms</th>\n",
       "      <th>processed_summaries</th>\n",
       "      <th>tokenized_summaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
       "      <td>Stereo matching is one of the widely used tech...</td>\n",
       "      <td>['cs.CV', 'cs.LG']</td>\n",
       "      <td>stereo matching is one of the widely used tech...</td>\n",
       "      <td>[stereo, matching, is, one, of, the, widely, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
       "      <td>The recent advancements in artificial intellig...</td>\n",
       "      <td>['cs.CV', 'cs.AI', 'cs.LG']</td>\n",
       "      <td>the recent advancements in artificial intellig...</td>\n",
       "      <td>[the, recent, advancements, in, artificial, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
       "      <td>In this paper, we proposed a novel mutual cons...</td>\n",
       "      <td>['cs.CV', 'cs.AI']</td>\n",
       "      <td>in this paper we proposed a novel mutual consi...</td>\n",
       "      <td>[in, this, paper, we, proposed, a, novel, mutu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
       "      <td>Consistency training has proven to be an advan...</td>\n",
       "      <td>['cs.CV']</td>\n",
       "      <td>consistency training has proven to be an advan...</td>\n",
       "      <td>[consistency, training, has, proven, to, be, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Background-Foreground Segmentation for Interio...</td>\n",
       "      <td>To ensure safety in automated driving, the cor...</td>\n",
       "      <td>['cs.CV', 'cs.LG']</td>\n",
       "      <td>to ensure safety in automated driving the corr...</td>\n",
       "      <td>[to, ensure, safety, in, automated, driving, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              titles  \\\n",
       "0  Survey on Semantic Stereo Matching / Semantic ...   \n",
       "1  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
       "2  Enforcing Mutual Consistency of Hard Regions f...   \n",
       "3  Parameter Decoupling Strategy for Semi-supervi...   \n",
       "4  Background-Foreground Segmentation for Interio...   \n",
       "\n",
       "                                           summaries  \\\n",
       "0  Stereo matching is one of the widely used tech...   \n",
       "1  The recent advancements in artificial intellig...   \n",
       "2  In this paper, we proposed a novel mutual cons...   \n",
       "3  Consistency training has proven to be an advan...   \n",
       "4  To ensure safety in automated driving, the cor...   \n",
       "\n",
       "                         terms  \\\n",
       "0           ['cs.CV', 'cs.LG']   \n",
       "1  ['cs.CV', 'cs.AI', 'cs.LG']   \n",
       "2           ['cs.CV', 'cs.AI']   \n",
       "3                    ['cs.CV']   \n",
       "4           ['cs.CV', 'cs.LG']   \n",
       "\n",
       "                                 processed_summaries  \\\n",
       "0  stereo matching is one of the widely used tech...   \n",
       "1  the recent advancements in artificial intellig...   \n",
       "2  in this paper we proposed a novel mutual consi...   \n",
       "3  consistency training has proven to be an advan...   \n",
       "4  to ensure safety in automated driving the corr...   \n",
       "\n",
       "                                 tokenized_summaries  \n",
       "0  [stereo, matching, is, one, of, the, widely, u...  \n",
       "1  [the, recent, advancements, in, artificial, in...  \n",
       "2  [in, this, paper, we, proposed, a, novel, mutu...  \n",
       "3  [consistency, training, has, proven, to, be, a...  \n",
       "4  [to, ensure, safety, in, automated, driving, t...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "data['tokenized_summaries'] = data['processed_summaries'].apply(word_tokenize)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c3d23d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(token_list):\n",
    "    return [word for word in token_list if word not in stop_words]\n",
    "data['filtered_summaries'] = data['tokenized_summaries'].apply(remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9a04b29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>summaries</th>\n",
       "      <th>terms</th>\n",
       "      <th>processed_summaries</th>\n",
       "      <th>tokenized_summaries</th>\n",
       "      <th>filtered_summaries</th>\n",
       "      <th>lemmatized_summaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
       "      <td>Stereo matching is one of the widely used tech...</td>\n",
       "      <td>['cs.CV', 'cs.LG']</td>\n",
       "      <td>stereo matching is one of the widely used tech...</td>\n",
       "      <td>[stereo, matching, is, one, of, the, widely, u...</td>\n",
       "      <td>[stereo, matching, one, widely, used, techniqu...</td>\n",
       "      <td>[stereo, matching, one, widely, used, techniqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
       "      <td>The recent advancements in artificial intellig...</td>\n",
       "      <td>['cs.CV', 'cs.AI', 'cs.LG']</td>\n",
       "      <td>the recent advancements in artificial intellig...</td>\n",
       "      <td>[the, recent, advancements, in, artificial, in...</td>\n",
       "      <td>[recent, advancements, artificial, intelligenc...</td>\n",
       "      <td>[recent, advancement, artificial, intelligence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
       "      <td>In this paper, we proposed a novel mutual cons...</td>\n",
       "      <td>['cs.CV', 'cs.AI']</td>\n",
       "      <td>in this paper we proposed a novel mutual consi...</td>\n",
       "      <td>[in, this, paper, we, proposed, a, novel, mutu...</td>\n",
       "      <td>[paper, proposed, novel, mutual, consistency, ...</td>\n",
       "      <td>[paper, proposed, novel, mutual, consistency, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
       "      <td>Consistency training has proven to be an advan...</td>\n",
       "      <td>['cs.CV']</td>\n",
       "      <td>consistency training has proven to be an advan...</td>\n",
       "      <td>[consistency, training, has, proven, to, be, a...</td>\n",
       "      <td>[consistency, training, proven, advanced, semi...</td>\n",
       "      <td>[consistency, training, proven, advanced, semi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Background-Foreground Segmentation for Interio...</td>\n",
       "      <td>To ensure safety in automated driving, the cor...</td>\n",
       "      <td>['cs.CV', 'cs.LG']</td>\n",
       "      <td>to ensure safety in automated driving the corr...</td>\n",
       "      <td>[to, ensure, safety, in, automated, driving, t...</td>\n",
       "      <td>[ensure, safety, automated, driving, correct, ...</td>\n",
       "      <td>[ensure, safety, automated, driving, correct, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              titles  \\\n",
       "0  Survey on Semantic Stereo Matching / Semantic ...   \n",
       "1  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
       "2  Enforcing Mutual Consistency of Hard Regions f...   \n",
       "3  Parameter Decoupling Strategy for Semi-supervi...   \n",
       "4  Background-Foreground Segmentation for Interio...   \n",
       "\n",
       "                                           summaries  \\\n",
       "0  Stereo matching is one of the widely used tech...   \n",
       "1  The recent advancements in artificial intellig...   \n",
       "2  In this paper, we proposed a novel mutual cons...   \n",
       "3  Consistency training has proven to be an advan...   \n",
       "4  To ensure safety in automated driving, the cor...   \n",
       "\n",
       "                         terms  \\\n",
       "0           ['cs.CV', 'cs.LG']   \n",
       "1  ['cs.CV', 'cs.AI', 'cs.LG']   \n",
       "2           ['cs.CV', 'cs.AI']   \n",
       "3                    ['cs.CV']   \n",
       "4           ['cs.CV', 'cs.LG']   \n",
       "\n",
       "                                 processed_summaries  \\\n",
       "0  stereo matching is one of the widely used tech...   \n",
       "1  the recent advancements in artificial intellig...   \n",
       "2  in this paper we proposed a novel mutual consi...   \n",
       "3  consistency training has proven to be an advan...   \n",
       "4  to ensure safety in automated driving the corr...   \n",
       "\n",
       "                                 tokenized_summaries  \\\n",
       "0  [stereo, matching, is, one, of, the, widely, u...   \n",
       "1  [the, recent, advancements, in, artificial, in...   \n",
       "2  [in, this, paper, we, proposed, a, novel, mutu...   \n",
       "3  [consistency, training, has, proven, to, be, a...   \n",
       "4  [to, ensure, safety, in, automated, driving, t...   \n",
       "\n",
       "                                  filtered_summaries  \\\n",
       "0  [stereo, matching, one, widely, used, techniqu...   \n",
       "1  [recent, advancements, artificial, intelligenc...   \n",
       "2  [paper, proposed, novel, mutual, consistency, ...   \n",
       "3  [consistency, training, proven, advanced, semi...   \n",
       "4  [ensure, safety, automated, driving, correct, ...   \n",
       "\n",
       "                                lemmatized_summaries  \n",
       "0  [stereo, matching, one, widely, used, techniqu...  \n",
       "1  [recent, advancement, artificial, intelligence...  \n",
       "2  [paper, proposed, novel, mutual, consistency, ...  \n",
       "3  [consistency, training, proven, advanced, semi...  \n",
       "4  [ensure, safety, automated, driving, correct, ...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_tokens(token_list):\n",
    "    return [lemmatizer.lemmatize(word) for word in token_list]\n",
    "data['lemmatized_summaries'] = data['filtered_summaries'].apply(lemmatize_tokens)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "16deed7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>summaries</th>\n",
       "      <th>terms</th>\n",
       "      <th>processed_summaries</th>\n",
       "      <th>tokenized_summaries</th>\n",
       "      <th>filtered_summaries</th>\n",
       "      <th>lemmatized_summaries</th>\n",
       "      <th>clean_summaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
       "      <td>Stereo matching is one of the widely used tech...</td>\n",
       "      <td>['cs.CV', 'cs.LG']</td>\n",
       "      <td>stereo matching is one of the widely used tech...</td>\n",
       "      <td>[stereo, matching, is, one, of, the, widely, u...</td>\n",
       "      <td>[stereo, matching, one, widely, used, techniqu...</td>\n",
       "      <td>[stereo, matching, one, widely, used, techniqu...</td>\n",
       "      <td>stereo matching one widely used technique infe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
       "      <td>The recent advancements in artificial intellig...</td>\n",
       "      <td>['cs.CV', 'cs.AI', 'cs.LG']</td>\n",
       "      <td>the recent advancements in artificial intellig...</td>\n",
       "      <td>[the, recent, advancements, in, artificial, in...</td>\n",
       "      <td>[recent, advancements, artificial, intelligenc...</td>\n",
       "      <td>[recent, advancement, artificial, intelligence...</td>\n",
       "      <td>recent advancement artificial intelligence ai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
       "      <td>In this paper, we proposed a novel mutual cons...</td>\n",
       "      <td>['cs.CV', 'cs.AI']</td>\n",
       "      <td>in this paper we proposed a novel mutual consi...</td>\n",
       "      <td>[in, this, paper, we, proposed, a, novel, mutu...</td>\n",
       "      <td>[paper, proposed, novel, mutual, consistency, ...</td>\n",
       "      <td>[paper, proposed, novel, mutual, consistency, ...</td>\n",
       "      <td>paper proposed novel mutual consistency networ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
       "      <td>Consistency training has proven to be an advan...</td>\n",
       "      <td>['cs.CV']</td>\n",
       "      <td>consistency training has proven to be an advan...</td>\n",
       "      <td>[consistency, training, has, proven, to, be, a...</td>\n",
       "      <td>[consistency, training, proven, advanced, semi...</td>\n",
       "      <td>[consistency, training, proven, advanced, semi...</td>\n",
       "      <td>consistency training proven advanced semisuper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Background-Foreground Segmentation for Interio...</td>\n",
       "      <td>To ensure safety in automated driving, the cor...</td>\n",
       "      <td>['cs.CV', 'cs.LG']</td>\n",
       "      <td>to ensure safety in automated driving the corr...</td>\n",
       "      <td>[to, ensure, safety, in, automated, driving, t...</td>\n",
       "      <td>[ensure, safety, automated, driving, correct, ...</td>\n",
       "      <td>[ensure, safety, automated, driving, correct, ...</td>\n",
       "      <td>ensure safety automated driving correct percep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              titles  \\\n",
       "0  Survey on Semantic Stereo Matching / Semantic ...   \n",
       "1  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
       "2  Enforcing Mutual Consistency of Hard Regions f...   \n",
       "3  Parameter Decoupling Strategy for Semi-supervi...   \n",
       "4  Background-Foreground Segmentation for Interio...   \n",
       "\n",
       "                                           summaries  \\\n",
       "0  Stereo matching is one of the widely used tech...   \n",
       "1  The recent advancements in artificial intellig...   \n",
       "2  In this paper, we proposed a novel mutual cons...   \n",
       "3  Consistency training has proven to be an advan...   \n",
       "4  To ensure safety in automated driving, the cor...   \n",
       "\n",
       "                         terms  \\\n",
       "0           ['cs.CV', 'cs.LG']   \n",
       "1  ['cs.CV', 'cs.AI', 'cs.LG']   \n",
       "2           ['cs.CV', 'cs.AI']   \n",
       "3                    ['cs.CV']   \n",
       "4           ['cs.CV', 'cs.LG']   \n",
       "\n",
       "                                 processed_summaries  \\\n",
       "0  stereo matching is one of the widely used tech...   \n",
       "1  the recent advancements in artificial intellig...   \n",
       "2  in this paper we proposed a novel mutual consi...   \n",
       "3  consistency training has proven to be an advan...   \n",
       "4  to ensure safety in automated driving the corr...   \n",
       "\n",
       "                                 tokenized_summaries  \\\n",
       "0  [stereo, matching, is, one, of, the, widely, u...   \n",
       "1  [the, recent, advancements, in, artificial, in...   \n",
       "2  [in, this, paper, we, proposed, a, novel, mutu...   \n",
       "3  [consistency, training, has, proven, to, be, a...   \n",
       "4  [to, ensure, safety, in, automated, driving, t...   \n",
       "\n",
       "                                  filtered_summaries  \\\n",
       "0  [stereo, matching, one, widely, used, techniqu...   \n",
       "1  [recent, advancements, artificial, intelligenc...   \n",
       "2  [paper, proposed, novel, mutual, consistency, ...   \n",
       "3  [consistency, training, proven, advanced, semi...   \n",
       "4  [ensure, safety, automated, driving, correct, ...   \n",
       "\n",
       "                                lemmatized_summaries  \\\n",
       "0  [stereo, matching, one, widely, used, techniqu...   \n",
       "1  [recent, advancement, artificial, intelligence...   \n",
       "2  [paper, proposed, novel, mutual, consistency, ...   \n",
       "3  [consistency, training, proven, advanced, semi...   \n",
       "4  [ensure, safety, automated, driving, correct, ...   \n",
       "\n",
       "                                     clean_summaries  \n",
       "0  stereo matching one widely used technique infe...  \n",
       "1  recent advancement artificial intelligence ai ...  \n",
       "2  paper proposed novel mutual consistency networ...  \n",
       "3  consistency training proven advanced semisuper...  \n",
       "4  ensure safety automated driving correct percep...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rejoin_tokens(token_list):\n",
    "    return ' '.join(token_list)\n",
    "data['clean_summaries'] = data['lemmatized_summaries'].apply(rejoin_tokens)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dccb3c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of step-by-step vs pipeline approach:\n",
      "                                     clean_summaries  \\\n",
      "0  stereo matching one widely used technique infe...   \n",
      "1  recent advancement artificial intelligence ai ...   \n",
      "2  paper proposed novel mutual consistency networ...   \n",
      "3  consistency training proven advanced semisuper...   \n",
      "4  ensure safety automated driving correct percep...   \n",
      "5  highquality training data play key role image ...   \n",
      "6  semantic segmentation fineresolution urban sce...   \n",
      "7  mitigate radiologist workload computeraided di...   \n",
      "8  generalising deep model new data new centre te...   \n",
      "9  success deep learning method medical image seg...   \n",
      "\n",
      "                            clean_summaries_pipeline  \n",
      "0  stereo matching one widely used technique infe...  \n",
      "1  recent advancement artificial intelligence ai ...  \n",
      "2  paper proposed novel mutual consistency networ...  \n",
      "3  consistency training proven advanced semisuper...  \n",
      "4  ensure safety automated driving correct percep...  \n",
      "5  highquality training data play key role image ...  \n",
      "6  semantic segmentation fineresolution urban sce...  \n",
      "7  mitigate radiologist workload computeraided di...  \n",
      "8  generalising deep model new data new centre te...  \n",
      "9  success deep learning method medical image seg...  \n",
      "\n",
      "Consistency check (first 5 rows):\n",
      "Row 0: MATCH\n",
      "Row 1: MATCH\n",
      "Row 2: MATCH\n",
      "Row 3: MATCH\n",
      "Row 4: MATCH\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def nltk_preprocessing_pipeline(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"\n",
    "        \"\\U0001F300-\\U0001F5FF\"\n",
    "        \"\\U0001F680-\\U0001F6FF\"\n",
    "        \"\\U0001F1E0-\\U0001F1FF\"\n",
    "        \"\\U00002702-\\U000027B0\"\n",
    "        \"\\U000024C2-\\U0001F251\"\n",
    "        \"\\U0001f926-\\U0001f937\"\n",
    "        \"\\U00010000-\\U0010ffff\"\n",
    "        \"\\u2640-\\u2642\"\n",
    "        \"\\u2600-\\u2B55\"\n",
    "        \"\\u200d\"\n",
    "        \"\\u23cf\"\n",
    "        \"\\u23e9\"\n",
    "        \"\\u231a\"\n",
    "        \"\\ufe0f\"\n",
    "        \"\\u3030\"\n",
    "        \"]+\", re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "data['clean_summaries_pipeline'] = data['summaries'].apply(nltk_preprocessing_pipeline)\n",
    "\n",
    "comparison = data[['clean_summaries', 'clean_summaries_pipeline']].head(10)\n",
    "print(\"Comparison of step-by-step vs pipeline approach:\")\n",
    "print(comparison)\n",
    "print(\"\\nConsistency check (first 5 rows):\")\n",
    "for i in range(min(5, len(data))):\n",
    "    if data['clean_summaries'].iloc[i] == data['clean_summaries_pipeline'].iloc[i]:\n",
    "        print(f\"Row {i}: MATCH\")\n",
    "    else:\n",
    "        print(f\"Row {i}: MISMATCH\")\n",
    "        print(f\"  Step-by-step: {data['clean_summaries'].iloc[i][:100]}\")\n",
    "        print(f\"  Pipeline:     {data['clean_summaries_pipeline'].iloc[i][:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f2b749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9670ec62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>summaries</th>\n",
       "      <th>terms</th>\n",
       "      <th>processed_summaries</th>\n",
       "      <th>tokenized_summaries</th>\n",
       "      <th>filtered_summaries</th>\n",
       "      <th>lemmatized_summaries</th>\n",
       "      <th>clean_summaries</th>\n",
       "      <th>clean_summaries_pipeline</th>\n",
       "      <th>clean_summaries_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
       "      <td>Stereo matching is one of the widely used tech...</td>\n",
       "      <td>['cs.CV', 'cs.LG']</td>\n",
       "      <td>stereo matching is one of the widely used tech...</td>\n",
       "      <td>[stereo, matching, is, one, of, the, widely, u...</td>\n",
       "      <td>[stereo, matching, one, widely, used, techniqu...</td>\n",
       "      <td>[stereo, matching, one, widely, used, techniqu...</td>\n",
       "      <td>stereo matching one widely used technique infe...</td>\n",
       "      <td>stereo matching one widely used technique infe...</td>\n",
       "      <td>stereo matching widely technique infer depth s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
       "      <td>The recent advancements in artificial intellig...</td>\n",
       "      <td>['cs.CV', 'cs.AI', 'cs.LG']</td>\n",
       "      <td>the recent advancements in artificial intellig...</td>\n",
       "      <td>[the, recent, advancements, in, artificial, in...</td>\n",
       "      <td>[recent, advancements, artificial, intelligenc...</td>\n",
       "      <td>[recent, advancement, artificial, intelligence...</td>\n",
       "      <td>recent advancement artificial intelligence ai ...</td>\n",
       "      <td>recent advancement artificial intelligence ai ...</td>\n",
       "      <td>recent advancement artificial intelligence ai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
       "      <td>In this paper, we proposed a novel mutual cons...</td>\n",
       "      <td>['cs.CV', 'cs.AI']</td>\n",
       "      <td>in this paper we proposed a novel mutual consi...</td>\n",
       "      <td>[in, this, paper, we, proposed, a, novel, mutu...</td>\n",
       "      <td>[paper, proposed, novel, mutual, consistency, ...</td>\n",
       "      <td>[paper, proposed, novel, mutual, consistency, ...</td>\n",
       "      <td>paper proposed novel mutual consistency networ...</td>\n",
       "      <td>paper proposed novel mutual consistency networ...</td>\n",
       "      <td>paper propose novel mutual consistency network...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
       "      <td>Consistency training has proven to be an advan...</td>\n",
       "      <td>['cs.CV']</td>\n",
       "      <td>consistency training has proven to be an advan...</td>\n",
       "      <td>[consistency, training, has, proven, to, be, a...</td>\n",
       "      <td>[consistency, training, proven, advanced, semi...</td>\n",
       "      <td>[consistency, training, proven, advanced, semi...</td>\n",
       "      <td>consistency training proven advanced semisuper...</td>\n",
       "      <td>consistency training proven advanced semisuper...</td>\n",
       "      <td>consistency training prove advanced semisuperv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Background-Foreground Segmentation for Interio...</td>\n",
       "      <td>To ensure safety in automated driving, the cor...</td>\n",
       "      <td>['cs.CV', 'cs.LG']</td>\n",
       "      <td>to ensure safety in automated driving the corr...</td>\n",
       "      <td>[to, ensure, safety, in, automated, driving, t...</td>\n",
       "      <td>[ensure, safety, automated, driving, correct, ...</td>\n",
       "      <td>[ensure, safety, automated, driving, correct, ...</td>\n",
       "      <td>ensure safety automated driving correct percep...</td>\n",
       "      <td>ensure safety automated driving correct percep...</td>\n",
       "      <td>ensure safety automated drive correct percepti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              titles  \\\n",
       "0  Survey on Semantic Stereo Matching / Semantic ...   \n",
       "1  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
       "2  Enforcing Mutual Consistency of Hard Regions f...   \n",
       "3  Parameter Decoupling Strategy for Semi-supervi...   \n",
       "4  Background-Foreground Segmentation for Interio...   \n",
       "\n",
       "                                           summaries  \\\n",
       "0  Stereo matching is one of the widely used tech...   \n",
       "1  The recent advancements in artificial intellig...   \n",
       "2  In this paper, we proposed a novel mutual cons...   \n",
       "3  Consistency training has proven to be an advan...   \n",
       "4  To ensure safety in automated driving, the cor...   \n",
       "\n",
       "                         terms  \\\n",
       "0           ['cs.CV', 'cs.LG']   \n",
       "1  ['cs.CV', 'cs.AI', 'cs.LG']   \n",
       "2           ['cs.CV', 'cs.AI']   \n",
       "3                    ['cs.CV']   \n",
       "4           ['cs.CV', 'cs.LG']   \n",
       "\n",
       "                                 processed_summaries  \\\n",
       "0  stereo matching is one of the widely used tech...   \n",
       "1  the recent advancements in artificial intellig...   \n",
       "2  in this paper we proposed a novel mutual consi...   \n",
       "3  consistency training has proven to be an advan...   \n",
       "4  to ensure safety in automated driving the corr...   \n",
       "\n",
       "                                 tokenized_summaries  \\\n",
       "0  [stereo, matching, is, one, of, the, widely, u...   \n",
       "1  [the, recent, advancements, in, artificial, in...   \n",
       "2  [in, this, paper, we, proposed, a, novel, mutu...   \n",
       "3  [consistency, training, has, proven, to, be, a...   \n",
       "4  [to, ensure, safety, in, automated, driving, t...   \n",
       "\n",
       "                                  filtered_summaries  \\\n",
       "0  [stereo, matching, one, widely, used, techniqu...   \n",
       "1  [recent, advancements, artificial, intelligenc...   \n",
       "2  [paper, proposed, novel, mutual, consistency, ...   \n",
       "3  [consistency, training, proven, advanced, semi...   \n",
       "4  [ensure, safety, automated, driving, correct, ...   \n",
       "\n",
       "                                lemmatized_summaries  \\\n",
       "0  [stereo, matching, one, widely, used, techniqu...   \n",
       "1  [recent, advancement, artificial, intelligence...   \n",
       "2  [paper, proposed, novel, mutual, consistency, ...   \n",
       "3  [consistency, training, proven, advanced, semi...   \n",
       "4  [ensure, safety, automated, driving, correct, ...   \n",
       "\n",
       "                                     clean_summaries  \\\n",
       "0  stereo matching one widely used technique infe...   \n",
       "1  recent advancement artificial intelligence ai ...   \n",
       "2  paper proposed novel mutual consistency networ...   \n",
       "3  consistency training proven advanced semisuper...   \n",
       "4  ensure safety automated driving correct percep...   \n",
       "\n",
       "                            clean_summaries_pipeline  \\\n",
       "0  stereo matching one widely used technique infe...   \n",
       "1  recent advancement artificial intelligence ai ...   \n",
       "2  paper proposed novel mutual consistency networ...   \n",
       "3  consistency training proven advanced semisuper...   \n",
       "4  ensure safety automated driving correct percep...   \n",
       "\n",
       "                               clean_summaries_spacy  \n",
       "0  stereo matching widely technique infer depth s...  \n",
       "1  recent advancement artificial intelligence ai ...  \n",
       "2  paper propose novel mutual consistency network...  \n",
       "3  consistency training prove advanced semisuperv...  \n",
       "4  ensure safety automated drive correct percepti...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def spacy_preprocessing_pipeline(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"\n",
    "        \"\\U0001F300-\\U0001F5FF\"\n",
    "        \"\\U0001F680-\\U0001F6FF\"\n",
    "        \"\\U0001F1E0-\\U0001F1FF\"\n",
    "        \"\\U00002702-\\U000027B0\"\n",
    "        \"\\U000024C2-\\U0001F251\"\n",
    "        \"\\U0001f926-\\U0001f937\"\n",
    "        \"\\U00010000-\\U0010ffff\"\n",
    "        \"\\u2640-\\u2642\"\n",
    "        \"\\u2600-\\u2B55\"\n",
    "        \"\\u200d\"\n",
    "        \"\\u23cf\"\n",
    "        \"\\u23e9\"\n",
    "        \"\\u231a\"\n",
    "        \"\\ufe0f\"\n",
    "        \"\\u3030\"\n",
    "        \"]+\", re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    lemmatized_tokens = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    \n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "data['clean_summaries_spacy'] = data['summaries'].apply(spacy_preprocessing_pipeline)\n",
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
